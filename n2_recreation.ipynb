{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf71b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goal: Recreate N2 using custom ECFs\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "from coffea import processor\n",
    "import json\n",
    "import hist\n",
    "from coffea.nanoevents import NanoEventsFactory, BaseSchema, NanoAODSchema\n",
    "import matplotlib.pyplot as plt\n",
    "from lpcjobqueue import LPCCondorCluster\n",
    "from distributed import Client\n",
    "from coffea.lookup_tools.lookup_base import lookup_base\n",
    "from coffea import util\n",
    "import importlib.resources\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "import fastjet\n",
    "from custom_n2 import e2\n",
    "from e23_numba import e23_loop, e23_numba, e2_loop, e2_numba\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81229c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LPCCondorCluster(ship_env=True, \n",
    "                           transfer_input_files=['custom_ecf.py', 'ecf_numba.py'], \n",
    "                           #log_directory='/uscmst1b_scratch/lpc1/3DayLifetime/cjmoore/mylog',\n",
    "                           memory='1258291200'\n",
    "                          )        \n",
    "LPCCondorCluster()\n",
    "cluster.adapt(minimum=0, maximum=100)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e920e25c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(LPCCondorCluster.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc743c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ee7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json file with signal and background samples\n",
    "with open(\"jsons/filelist_sans_bad_files.json\") as fin:\n",
    "    filesets = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655378c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coffea processor\n",
    "from custom_ecf import e2, e23, distance\n",
    "from ecf_numba import e23_loop, e23_numba, e2_loop, e2_numba\n",
    "\n",
    "class MyProcessor(processor.ProcessorABC):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self, events):\n",
    "        dataset = events.metadata['dataset']\n",
    "       \n",
    "        fatjet = events.FatJet\n",
    "        pfcands = events.PFCands\n",
    "        fatjetpfcands = events.FatJetPFCands\n",
    "        \n",
    "        n2 = (\n",
    "            hist.Hist.new\n",
    "            .Reg(60, -1.4, 0.25, name='n2b1', label='N2B1')\n",
    "            .Double()\n",
    "        )\n",
    "        \n",
    "        n2.fill(n2b1=ak.flatten(fatjet.n2b1))\n",
    "        \n",
    "        custom_n2_mix = (\n",
    "            hist.Hist.new\n",
    "            .Reg(60, -1.4, 0.25, name='my_n2', label='my_n2_mix')\n",
    "            .Double()\n",
    "        )\n",
    "        \n",
    "        custom_n2_numba = (\n",
    "            hist.Hist.new\n",
    "            .Reg(60, -1.4, 0.25, name='my_n2', label='my_n2_numba')\n",
    "            .Double()\n",
    "        )\n",
    "        \n",
    "        custom_n2_awkward = (\n",
    "            hist.Hist.new\n",
    "            .Reg(60, -1.4, 0.25, name='my_n2', label='my_n2_awkward')\n",
    "            .Double()\n",
    "        )\n",
    "        \n",
    "        s_mass = (\n",
    "            hist.Hist.new\n",
    "            .Reg(40, 0, 200., name='softdrop_mass', label='FatJet_msoftdrop')\n",
    "            .Double()\n",
    "        )\n",
    "        \n",
    "        #fatjet['n2ddt'] = fatjet.n2b1 - n2ddt_shift(fatjet, year='2017')\n",
    "        fatjet['bespoke_n2b1_mix'] = e23_numba(fatjetpfcands, pfcands, fatjet)/(e2(fatjetpfcands, pfcands, fatjet)**2)\n",
    "        fatjet['bespoke_n2b1_numba'] = e23_numba(fatjetpfcands, pfcands, fatjet)/(e2_numba(fatjetpfcands, pfcands, fatjet)**2)\n",
    "        fatjet['bespoke_n2b1_awkward'] = e23(fatjetpfcands, pfcands, fatjet)/(e2(fatjetpfcands, pfcands, fatjet)**2)\n",
    "        #fatjet['e2'] = e2(fatjetpfcands, pfcands, fatjet)\n",
    "        #fatjet['e23'] = e23_numba(fatjetpfcands, pfcands, fatjet)\n",
    "        \n",
    "        custom_n2_mix.fill(my_n2=ak.flatten(fatjet.bespoke_n2b1_mix))\n",
    "        custom_n2_numba.fill(my_n2=ak.flatten(fatjet.bespoke_n2b1_numba))\n",
    "        custom_n2_awkward.fill(my_n2=ak.flatten(fatjet.bespoke_n2b1_awkward))\n",
    "        s_mass.fill(softdrop_mass=ak.flatten(fatjet.msoftdrop))\n",
    "        \n",
    "        return {\n",
    "            dataset: {\n",
    "                \"entries\": len(events),\n",
    "                \"n2b1\": n2,\n",
    "                \"custom_n2_mix\": custom_n2_mix,\n",
    "                \"softdrop_mass\": s_mass,\n",
    "                \"custom_n2_numba\": custom_n2_numba,\n",
    "                \"custom_n2_awkward\": custom_n2_awkward,\n",
    "            }\n",
    "        }\n",
    "    def postprocess(self, accumulator):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e5442",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Run processor on LPC condor\n",
    "processor_instance=MyProcessor()\n",
    "dask_run = processor.Runner(\n",
    "    executor = processor.DaskExecutor(client=client),\n",
    "    schema=NanoAODSchema,\n",
    "    chunksize = 1000,\n",
    "    maxchunks=500,\n",
    ")\n",
    "\n",
    "out = dask_run(\n",
    "    filesets,\n",
    "    \"Events\",\n",
    "    processor_instance=MyProcessor()\n",
    ")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f7114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"Found duplicate branch\")\n",
    "processor_instance=MyProcessor()\n",
    "run = processor.Runner(\n",
    "    executor = processor.FuturesExecutor(compression=None, workers=20),\n",
    "    schema=NanoAODSchema,\n",
    "    chunksize=500,\n",
    "    #maxchunks=500,\n",
    ")\n",
    "\n",
    "out = run(\n",
    "    filesets,\n",
    "    \"Events\",\n",
    "    processor_instance=MyProcessor()\n",
    ")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedacbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"n2_.pkl\",\"wb\")\n",
    "\n",
    "# write the python object (dict) to pickle file\n",
    "pickle.dump(out,f)\n",
    "\n",
    "# close file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1971f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"n2.pkl\", \"rb\")\n",
    "out = pickle.load(file)\n",
    "#out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d22561",
   "metadata": {},
   "outputs": [],
   "source": [
    "out['HJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4486cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd_n2b1 = (out['QCD_Pt_470to600_TuneCP5_13TeV_pythia8']['n2b1']+\n",
    "        out['QCD_Pt_600to800_TuneCP5_13TeV_pythia8']['n2b1']+\n",
    "        out['QCD_Pt_800to1000_TuneCP5_13TeV_pythia8']['n2b1']+\n",
    "        out['QCD_Pt_1000to1400_TuneCP5_13TeV_pythia8']['n2b1']+\n",
    "        out['QCD_Pt_1400to1800_TuneCP5_13TeV_pythia8']['n2b1']+\n",
    "        out['QCD_Pt_1800to2400_TuneCP5_13TeV_pythia8']['n2b1']+\n",
    "        out['QCD_Pt_2400to3200_TuneCP5_13TeV_pythia8']['n2b1']+\n",
    "        out['QCD_Pt_3200toInf_TuneCP5_13TeV_pythia8']['n2b1'])\n",
    "\n",
    "qcd_custom_n2 = (out['QCD_Pt_470to600_TuneCP5_13TeV_pythia8']['custom_n2']+\n",
    "        out['QCD_Pt_600to800_TuneCP5_13TeV_pythia8']['custom_n2']+\n",
    "        out['QCD_Pt_800to1000_TuneCP5_13TeV_pythia8']['custom_n2']+\n",
    "        out['QCD_Pt_1000to1400_TuneCP5_13TeV_pythia8']['custom_n2']+\n",
    "        out['QCD_Pt_1400to1800_TuneCP5_13TeV_pythia8']['custom_n2']+\n",
    "        out['QCD_Pt_1800to2400_TuneCP5_13TeV_pythia8']['custom_n2']+\n",
    "        out['QCD_Pt_2400to3200_TuneCP5_13TeV_pythia8']['custom_n2']+\n",
    "        out['QCD_Pt_3200toInf_TuneCP5_13TeV_pythia8']['custom_n2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60838de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "fig, ax = plt.subplots()\n",
    "#out['HJ']['n2b1'].plot1d(ax=ax)\n",
    "#out['HJ']['custom_n2'].plot1d(ax=ax)\n",
    "qcd_n2b1.plot1d(ax=ax)\n",
    "qcd_custom_n2.plot1d(ax=ax)\n",
    "ax.legend(['QCD n2',\n",
    "           'QCD custom n2'\n",
    "\n",
    "          ], \n",
    "           title='N2 Source'\n",
    "         )\n",
    "plt.title('QCD N2 Comparison')\n",
    "ax.set_xlim([-0.025,0.275])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9f503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
